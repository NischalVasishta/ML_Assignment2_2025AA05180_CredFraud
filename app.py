import streamlit as st
import pandas as pd
import numpy as np
import pickle

from sklearn.metrics import (
    accuracy_score, roc_auc_score, precision_score, recall_score,
    f1_score, matthews_corrcoef, confusion_matrix, classification_report
)

import matplotlib.pyplot as plt
import seaborn as sns

st.set_page_config(page_title="Credit Card Fraud - Model Demo", layout="wide")

st.title("Credit Card Fraud Detection (Model Comparison)")

@st.cache_resource
def load_assets():
    model_files = {
        "Logistic Regression": "logistic_regression.pkl",
        "Decision Tree": "decision_tree.pkl",
        "KNN": "knn.pkl",
        "Naive Bayes": "naive_bayes.pkl",
        "Random Forest": "random_forest.pkl",
        "XGBoost": "xgboost.pkl",
    }

    models = {}
    for display, path in model_files.items():
        with open(path, "rb") as f:
            models[display] = pickle.load(f)

    with open("scaler.pkl", "rb") as f:
        scaler = pickle.load(f)

    return models, scaler

models, scaler = load_assets()

st.sidebar.header("Inputs")
uploaded = st.sidebar.file_uploader("Upload test CSV (must include 'Class')", type=["csv"])  # [web:26]
model_name = st.sidebar.selectbox("Select model", list(models.keys()))

st.sidebar.markdown("---")
if st.sidebar.button("Load sample test_data.csv instructions"):
    st.sidebar.write("Use the test_data.csv generated by train_models.py (recommended).")

if uploaded is None:
    st.info("Upload a CSV to evaluate a model, or view the stored comparison table below.")
    try:
        results = pd.read_csv("model_results.csv", index_col=0)
        st.subheader("Saved model comparison (from training)")
        st.dataframe(results.style.format("{:.4f}"), use_container_width=True)
    except Exception:
        st.warning("model_results.csv not found. Run train_models.py first.")
    st.stop()

df = pd.read_csv(uploaded)

st.subheader("Uploaded data preview")
st.dataframe(df.head(), use_container_width=True)

if "Class" not in df.columns:
    st.error("Your uploaded CSV must contain the target column named 'Class'.")
    st.stop()

X = df.drop(columns=["Class"])
y = df["Class"].astype(int)

X_s = scaler.transform(X)

model = models[model_name]
y_pred = model.predict(X_s)

if hasattr(model, "predict_proba"):
    y_proba = model.predict_proba(X_s)[:, 1]
else:
    y_proba = y_pred.astype(float)

acc = accuracy_score(y, y_pred)
auc = roc_auc_score(y, y_proba)
prec = precision_score(y, y_pred, zero_division=0)
rec = recall_score(y, y_pred, zero_division=0)
f1 = f1_score(y, y_pred, zero_division=0)
mcc = matthews_corrcoef(y, y_pred)

st.subheader(f"Metrics: {model_name}")
c1, c2, c3 = st.columns(3)
c1.metric("Accuracy", f"{acc:.4f}")
c1.metric("AUC", f"{auc:.4f}")
c2.metric("Precision", f"{prec:.4f}")
c2.metric("Recall", f"{rec:.4f}")
c3.metric("F1", f"{f1:.4f}")
c3.metric("MCC", f"{mcc:.4f}")

left, right = st.columns(2)

with left:
    st.subheader("Confusion matrix")
    cm = confusion_matrix(y, y_pred)
    fig, ax = plt.subplots(figsize=(5.5, 4.5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")
    ax.set_xticklabels(["Legit (0)", "Fraud (1)"])
    ax.set_yticklabels(["Legit (0)", "Fraud (1)"])
    st.pyplot(fig)

with right:
    st.subheader("Classification report")
    report = classification_report(y, y_pred, output_dict=True, zero_division=0)
    rep_df = pd.DataFrame(report).transpose()
    st.dataframe(rep_df.style.format("{:.4f}"), use_container_width=True)